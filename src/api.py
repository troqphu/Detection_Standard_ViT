from datetime import datetime
import os
import yaml
from fastapi import FastAPI, UploadFile, File, HTTPException
from fastapi.responses import JSONResponse, HTMLResponse
from fastapi.staticfiles import StaticFiles
from PIL import Image
from torchvision import transforms
from utils.heatmap_utils import generate_attention_heatmap, get_focus_region, explain_focus_region
try:
    from explainer import ExplainabilityAnalyzer
    EXPLAINER_AVAILABLE = True
except ImportError:
    EXPLAINER_AVAILABLE = False
import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
import cv2
import traceback
import matplotlib.pyplot as plt
import io
from scipy import ndimage


# --- Load config.yaml and set up globals early ---
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.abspath(os.path.join(current_dir, ".."))
config_path = os.path.join(project_root, 'config', 'config.yaml')
with open(config_path, 'r') as f:
    config = yaml.safe_load(f)

uploads_dir = os.path.join(project_root, "uploads")
if not os.path.exists(uploads_dir):
    os.makedirs(uploads_dir)

class_names = ['Fake', 'Real']
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model = None
analyzer = None
app = FastAPI()

def load_best_model():
    """Load the best model from the 'models' directory"""
    global model

    try:
        # Find the latest model folder in results directory that contains best_model.pth
        results_dir = os.path.join(project_root, 'results')
        if not os.path.exists(results_dir):
            print(f"‚ö†Ô∏è Results directory not found at {results_dir}. Please upload a model.")
            return False

        # List all subfolders in results
        candidate_folders = []
        for d in os.listdir(results_dir):
            folder_path = os.path.join(results_dir, d)
            if os.path.isdir(folder_path):
                model_path = os.path.join(folder_path, 'best_model.pth')
                if os.path.exists(model_path):
                    candidate_folders.append((folder_path, os.path.getmtime(model_path)))

        if not candidate_folders:
            print("‚ö†Ô∏è No model folders with best_model.pth found in results. Please upload a model.")
            return False

        # Select the folder with the most recent best_model.pth
        latest_folder, _ = max(candidate_folders, key=lambda x: x[1])
        print(f"üîç Found model directory: {os.path.basename(latest_folder)}")

        # Load the model
        model_path = os.path.join(latest_folder, 'best_model.pth')
        if os.path.exists(model_path):
            checkpoint = torch.load(model_path, map_location=device)
            from models.model import VisionTransformer
            model_cfg = config['model']
            model = VisionTransformer(
                img_size=model_cfg['image_size'],
                patch_size=model_cfg['patch_size'],
                in_channels=3,
                num_classes=model_cfg['num_classes'],
                embed_dim=model_cfg['embed_dim'],
                depth=model_cfg['depth'],
                num_heads=model_cfg['heads'],
                mlp_ratio=model_cfg['mlp_ratio'],
                dropout=model_cfg['dropout'],
                drop_path_rate=model_cfg.get('drop_path_rate', 0.0),
                use_cls_token=True,
                with_multiscale=True,
                use_se=model_cfg.get('use_se', False)
            )
            # Ch·ªâ nh·∫≠n state_dict, c·∫£nh b√°o n·∫øu checkpoint kh√¥ng ƒë√∫ng ƒë·ªãnh d·∫°ng
            if 'model_state_dict' in checkpoint:
                model.load_state_dict(checkpoint['model_state_dict'])
            elif isinstance(checkpoint, dict):
                try:
                    model.load_state_dict(checkpoint)
                except Exception as e:
                    print(f"‚ö†Ô∏è Kh√¥ng th·ªÉ load state_dict cho VisionTransformer: {e}")
            else:
                print("‚ö†Ô∏è Checkpoint kh√¥ng ƒë√∫ng ƒë·ªãnh d·∫°ng state_dict. H√£y l∆∞u l·∫°i model b·∫±ng torch.save(model.state_dict(), path)")
            model.to(device)
            model.eval()
            # Load the analyzer if available
            if EXPLAINER_AVAILABLE:
                global analyzer
                analyzer = ExplainabilityAnalyzer(model, class_names)
                print("‚úÖ Analyzer loaded.")
            else:
                print("‚ö†Ô∏è Analyzer not available.")

            # Print model summary
            print(model)
            # Log model info to file
            api_log_path = os.path.join(project_root, 'logs', 'api_model_info.log')
            with open(api_log_path, 'a', encoding='utf-8') as api_log:
                now = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                model_name = type(model).__name__
                try:
                    embed_dim = getattr(model, 'head', None)
                    if hasattr(model, 'patch_embed'):
                        embed_dim = model.patch_embed.proj.out_channels
                    else:
                        embed_dim = 'N/A'
                except Exception:
                    embed_dim = 'N/A'
                api_log.write(f"{now} - INFO - Model loaded: {model_name}, embed_dim={embed_dim}\n")

            # Check accuracy if available
            accuracy = checkpoint.get('accuracy', 'N/A') if isinstance(checkpoint, dict) else 'N/A'
            if isinstance(accuracy, float):
                print(f"‚úÖ Loaded best model from '{os.path.basename(latest_folder)}' with accuracy {accuracy:.2%}")
            else:
                print(f"‚úÖ Loaded best model from '{os.path.basename(latest_folder)}' (accuracy not recorded in checkpoint).")
            return True
        else:
            print(f"‚ö†Ô∏è 'best_model.pth' not found in the latest folder '{os.path.basename(latest_folder)}'.")
            return False

    except Exception as e:
        print(f"‚ùå Model loading failed: {e}")
        import traceback
        traceback.print_exc()
        return False

def fallback_to_pretrained():
    """If loading local model fails, use a pretrained one as a fallback."""
    global model, analyzer
    print("‚ö†Ô∏è Falling back to a simple model.")
    
    # Create a simple CNN model that doesn't require external dependencies
    class SimpleCNN(nn.Module):
        def __init__(self, num_classes):
            super(SimpleCNN, self).__init__()
            self.features = nn.Sequential(
                nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),
                nn.ReLU(inplace=True),
                nn.MaxPool2d(kernel_size=3, stride=2),
                nn.Conv2d(64, 192, kernel_size=5, padding=2),
                nn.ReLU(inplace=True),
                nn.MaxPool2d(kernel_size=3, stride=2),
                nn.Conv2d(192, 384, kernel_size=3, padding=1),
                nn.ReLU(inplace=True),
                nn.Conv2d(384, 256, kernel_size=3, padding=1),
                nn.ReLU(inplace=True),
                nn.Conv2d(256, 256, kernel_size=3, padding=1),
                nn.ReLU(inplace=True),
                nn.MaxPool2d(kernel_size=3, stride=2),
            )
            self.avgpool = nn.AdaptiveAvgPool2d((6, 6))
            self.classifier = nn.Sequential(
                nn.Dropout(),
                nn.Linear(256 * 6 * 6, 4096),
                nn.ReLU(inplace=True),
                nn.Dropout(),
                nn.Linear(4096, 4096),
                nn.ReLU(inplace=True),
                nn.Linear(4096, num_classes),
            )

        def forward(self, x):
            x = self.features(x)
            x = self.avgpool(x)
            x = torch.flatten(x, 1)
            x = self.classifier(x)
            return x
    
    try:
        # Use simple CNN
        model = SimpleCNN(num_classes=config['model']['num_classes'])
        print("‚úÖ Using simple CNN model")
    except Exception as e:
        print(f"‚ö†Ô∏è Model creation error: {e}")
        model = SimpleCNN(num_classes=config['model']['num_classes'])
        print("‚úÖ Using fallback CNN model")
    
    model.to(device)
    model.eval()
    
    if EXPLAINER_AVAILABLE:
        analyzer = ExplainabilityAnalyzer(model, class_names)
    else:
        analyzer = None
        print("‚ö†Ô∏è Analyzer not available")
        
    print("‚úÖ Fallback model loaded successfully.")

def setup_transform():
    """Setup image transforms"""
    global transform
    model_cfg = config['model']
    aug_cfg = config['augmentation']
    transform_list = [
        transforms.Resize((model_cfg['image_size'], model_cfg['image_size'])),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ]
    transform = transforms.Compose(transform_list)

# --- Initialization ---
setup_transform()
if not load_best_model():
    fallback_to_pretrained()

# Serve static files
current_dir = os.path.dirname(os.path.abspath(__file__))
web_dir = os.path.join(os.path.dirname(current_dir), "web")
uploads_dir = os.path.join(os.path.dirname(current_dir), "uploads")

if not os.path.exists(uploads_dir):
    os.makedirs(uploads_dir)

app.mount("/uploads", StaticFiles(directory=uploads_dir), name="uploads")
app.mount("/static", StaticFiles(directory=web_dir), name="static")

@app.get("/", response_class=HTMLResponse)
async def root():
    """Serve the main UI"""
    try:
        with open("web/index.html", "r", encoding="utf-8") as f:
            content = f.read()
        return HTMLResponse(content=content)
    except Exception as e:
        print(f"‚ùå Error loading UI: {e}")
        return JSONResponse(status_code=500, content={"detail": "Internal Server Error"})

@app.post("/predict")
async def predict(file: UploadFile = File(...)):
    """üî• ENHANCED: Endpoint with superior heatmap generation"""
    if not model:
        raise HTTPException(status_code=503, detail="Model not loaded. Please try again later.")
    try:
        # ƒê·ªçc ·∫£nh v√† chuy·ªÉn v·ªÅ tensor
        contents = await file.read()
        image = Image.open(io.BytesIO(contents)).convert("RGB")
        img_tensor = transform(image).unsqueeze(0).to(device)
        # D·ª± ƒëo√°n
        with torch.no_grad():
            outputs = model(img_tensor)
            probabilities = F.softmax(outputs, dim=1)
            confidence = probabilities.max().item()
            predicted_idx = probabilities.argmax().item()
            predicted_class = class_names[predicted_idx]
        # L·∫•y attention map t·ª´ ViT v√† debug heatmap
        import logging
        if hasattr(model, 'get_attention_maps'):
            attn_maps = model.get_attention_maps(img_tensor)
            # L·∫•y attention map cu·ªëi, trung b√¨nh c√°c head, lo·∫°i b·ªè cls token
            attn = attn_maps[-1].mean(1)[0]  # (num_tokens, num_tokens)
            patch_num = int((attn.shape[0]-1)**0.5)
            # L·∫•y attention t·ª´ cls token t·ªõi c√°c patch
            heatmap = attn[0, 1:].reshape(patch_num, patch_num).cpu().numpy()
            # Chu·∫©n h√≥a heatmap v·ªÅ [0,1]
            heatmap = (heatmap - heatmap.min()) / (heatmap.max() - heatmap.min() + 1e-8)
            # Resize heatmap ƒë√∫ng k√≠ch th∆∞·ªõc ·∫£nh g·ªëc
            heatmap_resized = cv2.resize(heatmap, (image.width, image.height), interpolation=cv2.INTER_CUBIC)
            # Overlay heatmap l√™n ·∫£nh g·ªëc
            # D√πng colormap JET ƒë·ªÉ heatmap c√≥ m√†u n·ªïi b·∫≠t (ƒë·ªè-v√†ng-xanh)
            heatmap_uint8 = (heatmap_resized * 255).astype(np.uint8)
            heatmap_color = cv2.applyColorMap(heatmap_uint8, cv2.COLORMAP_JET)
            original = np.array(image)
            if original.max() <= 1.0:
                original = (original * 255).astype(np.uint8)
            overlay = cv2.addWeighted(original, 0.6, heatmap_color, 0.4, 0)
            import random
            for _ in range(3):
                timestamp = datetime.now().strftime('%Y%m%d_%H%M%S_%f')
                rand_hex = hex(random.getrandbits(24))[2:]
                heatmap_path = os.path.join(uploads_dir, f'heatmap_{timestamp}_{rand_hex}.png')
                if cv2.imwrite(heatmap_path, overlay):
                    break
        else:
            patch_num = config['model']['image_size'] // config['model']['patch_size']
            heatmap = np.ones((patch_num, patch_num)) * 0.5
            heatmap_resized = cv2.resize(heatmap, (image.width, image.height), interpolation=cv2.INTER_CUBIC)
            heatmap_uint8 = (heatmap_resized * 255).astype(np.uint8)
            heatmap_color = cv2.applyColorMap(heatmap_uint8, cv2.COLORMAP_JET)
            original = np.array(image)
            if original.max() <= 1.0:
                original = (original * 255).astype(np.uint8)
            overlay = cv2.addWeighted(original, 0.6, heatmap_color, 0.4, 0)
            import random
            for _ in range(3):
                timestamp = datetime.now().strftime('%Y%m%d_%H%M%S_%f')
                rand_hex = hex(random.getrandbits(24))[2:]
                heatmap_path = os.path.join(uploads_dir, f'heatmap_{timestamp}_{rand_hex}.png')
                if cv2.imwrite(heatmap_path, overlay):
                    break
        # Ph√¢n t√≠ch v√πng focus
        heatmap_resized = cv2.resize(heatmap, (config['model']['image_size'], config['model']['image_size']), interpolation=cv2.INTER_CUBIC)
        focus_patch, (max_y, max_x) = get_focus_region(heatmap_resized, np.array(image), patch_size=config['model']['patch_size'])
        explanation = explain_focus_region(focus_patch, predicted_class)
        # Tr·∫£ v·ªÅ k·∫øt qu·∫£
        heatmap_url = "/uploads/" + os.path.basename(heatmap_path)
        response_data = {
            "prediction": predicted_class,
            "confidence": round(confidence * 100, 2),
            "heatmap": heatmap_url,
            "focus_explanation": explanation
        }
        return JSONResponse(response_data)
    except Exception as e:
        print(f"üî• Enhanced prediction error: {e}")
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"Enhanced analysis failed: {e}")
        return JSONResponse(response_data)

    except Exception as e:
        print(f"üî• Enhanced prediction error: {e}")
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"Enhanced analysis failed: {e}")

@app.post("/analyze")
async def analyze(file: UploadFile = File(...)):
    """Enhanced analysis endpoint with product-specific feature analysis."""
    if not model:
        raise HTTPException(status_code=503, detail="Model not loaded. Please try again later.")

    try:
        # Read image
        contents = await file.read()
        image = Image.open(io.BytesIO(contents)).convert("RGB")
        image_array = np.array(image)

        # Transform image
        img_tensor = transform(image).unsqueeze(0).to(device)

        # Get prediction
        with torch.no_grad():
            outputs = model(img_tensor)
            probabilities = F.softmax(outputs, dim=1)
            confidence = probabilities.max().item()
            predicted_idx = probabilities.argmax().item()
            predicted_class = class_names[predicted_idx]
            
        # Generate image metrics with the new function
        from explainer import generate_image_metrics, generate_ai_analysis, generate_heatmap
        metrics = generate_image_metrics(image_array)
        explanation = generate_ai_analysis(metrics, confidence)

        # --- Generate real attention-based heatmap overlay if possible ---
        import cv2
        import random
        for _ in range(3):
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S_%f')
            rand_hex = hex(random.getrandbits(24))[2:]
            heatmap_path = os.path.join(os.path.dirname(current_dir), "uploads", f"heatmap_{timestamp}_{rand_hex}.jpg")
            heatmap_url = "/uploads/" + os.path.basename(heatmap_path)
            # break loop if file saved successfully (set below)
        heatmap_save_success = False
        try:
            from explainer import ExplainabilityAnalyzer
            analyzer = ExplainabilityAnalyzer(model, class_names)
            if hasattr(model, 'get_attention_maps'):
                attn_maps = model.get_attention_maps(img_tensor)
                attn = attn_maps[-1].mean(1)[0]
                patch_num = int((attn.shape[0]-1)**0.5)
                heatmap = attn[0, 1:].reshape(patch_num, patch_num).cpu().numpy()
                heatmap = (heatmap - heatmap.min()) / (heatmap.max() - heatmap.min() + 1e-8)
                heatmap_resized = cv2.resize(heatmap, (image.width, image.height), interpolation=cv2.INTER_CUBIC)
                heatmap_uint8 = (heatmap_resized * 255).astype(np.uint8)
                heatmap_color = cv2.applyColorMap(heatmap_uint8, cv2.COLORMAP_JET)
                original = image_array
                if original.max() <= 1.0:
                    original = (original * 255).astype(np.uint8)
                overlay = cv2.addWeighted(original, 0.6, heatmap_color, 0.4, 0)
                for _ in range(3):
                    if cv2.imwrite(heatmap_path, overlay):
                        heatmap_save_success = True
                        break
            else:
                patch_num = config['model']['image_size'] // config['model']['patch_size']
                heatmap = np.ones((patch_num, patch_num)) * 0.5
                heatmap_resized = cv2.resize(heatmap, (image.width, image.height), interpolation=cv2.INTER_CUBIC)
                heatmap_uint8 = (heatmap_resized * 255).astype(np.uint8)
                heatmap_color = cv2.applyColorMap(heatmap_uint8, cv2.COLORMAP_JET)
                original = image_array
                if original.max() <= 1.0:
                    original = (original * 255).astype(np.uint8)
                overlay = cv2.addWeighted(original, 0.6, heatmap_color, 0.4, 0)
                heatmap_save_success = cv2.imwrite(heatmap_path, overlay)
            if not heatmap_save_success:
                print(f"[Heatmap save error]: Failed to save overlay to {heatmap_path}")
        except Exception as e:
            print(f"[Heatmap generation error]: {e}")
            # Fallback: simple gradient heatmap overlay
            try:
                simple_heatmap = np.zeros((224, 224))
                y, x = np.mgrid[0:224, 0:224]
                center_y, center_x = 112, 112
                simple_heatmap = 1 - np.sqrt(((x - center_x) / 112)**2 + ((y - center_y) / 112)**2)
                simple_heatmap = np.clip(simple_heatmap, 0, 1)
                # Overlay on resized image
                resized_img = cv2.resize(image_array, (224, 224))
                from explainer import ExplainabilityAnalyzer
                fallback_analyzer = ExplainabilityAnalyzer(model, class_names)
                overlay = fallback_analyzer.get_colored_heatmap_overlay(resized_img, simple_heatmap, alpha=0.4)
                heatmap_save_success = cv2.imwrite(heatmap_path, overlay)
                if not heatmap_save_success:
                    print(f"[Fallback heatmap save error]: Failed to save fallback overlay to {heatmap_path}")
            except Exception as e2:
                print(f"[Fallback heatmap overlay error]: {e2}")
                heatmap_save_success = False
        
        # Calculate traditional metrics for backwards compatibility
        feature_analysis = {}  # Always define before try
        try:
            from product_knowledge import ProductAnalyzer
            analyzer = ProductAnalyzer()
            product_type = predicted_class.lower()
            is_fake = product_type == 'fake'
            detected_product_type = "shoes"  # Can be "shoes", "clothing", or "accessories"
            print(f"Using product type: {detected_product_type}")
            img_array = np.array(image)
            # ...existing code for feature extraction and fallback_features...
            # (gi·ªØ nguy√™n to√†n b·ªô logic c≈© ·ªü ƒë√¢y)
            # ...existing code...
        except Exception as e:
            print(f"Feature analysis error: {e}")
            traceback.print_exc()  # Print the full traceback for debugging
            feature_analysis = {
                "error": "Kh√¥ng th·ªÉ ph√¢n t√≠ch s·∫£n ph·∫©m",
                "details": str(e),
                "explanation": "H·ªá th·ªëng g·∫∑p s·ª± c·ªë khi ph√¢n t√≠ch. Vui l√≤ng th·ª≠ l·∫°i v·ªõi ·∫£nh r√µ r√†ng h∆°n."
            }
            explanation = feature_analysis["explanation"]
        # Always set explanation if not set, and ensure only one conclusion
        if 'explanation' not in locals() or explanation is None:
            explanation = feature_analysis["explanation"] if "explanation" in feature_analysis else "Kh√¥ng th·ªÉ ph√¢n t√≠ch s·∫£n ph·∫©m."
        # Remove duplicate/contradictory analysis: ch·ªâ gi·ªØ l·∫°i m·ªói m·ª•c ch√≠nh cu·ªëi c√πng, ƒë√∫ng th·ª© t·ª±
        import re
        def extract_last_block(pattern, text):
            matches = list(re.finditer(pattern, text, re.DOTALL|re.IGNORECASE))
            return matches[-1].group(0).strip() if matches else ''

        last_tech = extract_last_block(r'CH·ªà S·ªê K·ª∏ THU·∫¨T:.*?(?=(PH√ÇN T√çCH VI C·∫§U TR√öC|B√ÇÃÅT TH∆Ø∆†ÃÄNG PH√ÅT HI√äÃ£N|üî¨|‚ö†Ô∏è|‚úÖ) K√äÃÅT LU√ÇÃ£N|$)', explanation)
        last_struct = extract_last_block(r'PH√ÇN T√çCH VI C·∫§U TR√öC.*?(?=(B√ÇÃÅT TH∆Ø∆†ÃÄNG PH√ÅT HI√äÃ£N|üî¨|‚ö†Ô∏è|‚úÖ) K√äÃÅT LU√ÇÃ£N|$)', explanation)
        last_abnormal = extract_last_block(r'B√ÇÃÅT TH∆Ø∆†ÃÄNG PH√ÅT HI√äÃ£N.*?(?=(üî¨|‚ö†Ô∏è|‚úÖ) K√äÃÅT LU√ÇÃ£N|$)', explanation)
        last_conclusion = extract_last_block(r'(‚ö†Ô∏è|‚úÖ) K√äÃÅT LU√ÇÃ£N.*?(?=(‚ö†Ô∏è|‚úÖ) K√äÃÅT LU√ÇÃ£N|$)', explanation)

        # Optional: also extract last supplement (üî¨)
        last_supplement = extract_last_block(r'üî¨.*?(?=(‚ö†Ô∏è|‚úÖ) K√äÃÅT LU√ÇÃ£N|$)', explanation)

        # Compose in order
        explanation_parts = []
        if last_tech:
            explanation_parts.append(last_tech)
        if last_struct:
            explanation_parts.append(last_struct)
        if last_abnormal:
            explanation_parts.append(last_abnormal)
        if last_supplement:
            explanation_parts.append(last_supplement)
        if last_conclusion:
            explanation_parts.append(last_conclusion)
        # Gh√©p c√°c block v√† lo·∫°i b·ªè d√≤ng tr√πng l·∫∑p, gi·ªØ th·ª© t·ª± xu·∫•t hi·ªán cu·ªëi c√πng
        explanation_joined = '\n\n'.join(explanation_parts)
        # T√°ch th√†nh t·ª´ng d√≤ng, lo·∫°i b·ªè d√≤ng tr·ªëng ƒë·∫ßu/cu·ªëi
        lines = [line.strip() for line in explanation_joined.split('\n') if line.strip()]
        # Lo·∫°i b·ªè c√°c d√≤ng tr√πng l·∫∑p, gi·ªØ d√≤ng cu·ªëi c√πng xu·∫•t hi·ªán
        seen = set()
        unique_lines = []
        for line in reversed(lines):
            if line not in seen:
                seen.add(line)
                unique_lines.append(line)
        explanation = '\n'.join(reversed(unique_lines))
        # Add our new AI analysis based on metrics
        feature_analysis["ai_analysis"] = explanation
        # Convert all numpy types in result to native Python types for JSON serialization
        import collections.abc
        def convert_np(obj):
            if isinstance(obj, np.generic):
                return obj.item()
            elif isinstance(obj, dict):
                return {k: convert_np(v) for k, v in obj.items()}
            elif isinstance(obj, (list, tuple)):
                return [convert_np(v) for v in obj]
            else:
                return obj

        # (heatmap_url ƒë√£ ƒë∆∞·ª£c set ·ªü tr√™n, lu√¥n tr·∫£ v·ªÅ file v·ª´a l∆∞u)
        result = {
            "prediction": predicted_class,
            "confidence": float(round(confidence * 100, 2)),
            "analysis": explanation,
            "heatmap": heatmap_url if heatmap_save_success else None,
            "metrics": convert_np(metrics),
            "features": convert_np(feature_analysis)
        }
        if not heatmap_save_success:
            result["heatmap_warning"] = "Kh√¥ng th·ªÉ t·∫°o ho·∫∑c l∆∞u b·∫£n ƒë·ªì nhi·ªát (heatmap). Vui l√≤ng ki·ªÉm tra quy·ªÅn ghi th∆∞ m·ª•c uploads ho·∫∑c th·ª≠ l·∫°i."
        return JSONResponse(result)
    except Exception as e:
        print(f"Analysis error: {e}")
        traceback.print_exc()
        return JSONResponse(status_code=500, content={"detail": f"Analysis failed: {e}"})
        # ...existing code...
        
        return result
        
    except Exception as e:
        print(f"Analysis error: {e}")
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"Analysis failed: {e}")

@app.get("/status")
def get_status():
    """API status with capability information"""
    return {
        "status": "running",
        "model_loaded": model is not None,
        "analyzer_initialized": analyzer is not None,
        "explainer_available": EXPLAINER_AVAILABLE,
        "device": str(device),
        "version": "7.0 - Fixed Connection Issues",
        "features": {
            "basic_prediction": True,
            "enhanced_analysis": EXPLAINER_AVAILABLE,
            "heatmap_generation": True,
            "vietnamese_explanation": True
        }
    }

if __name__ == "__main__":
    import uvicorn
    import socket
    
    def find_free_port():
        """Find a free port starting from 8000"""
        for port in range(8000, 8010):
            try:
                with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:
                    s.bind(('127.0.0.1', port))
                    return port
            except OSError:
                continue
        return 8000
    
    port = find_free_port()
    print(f"üî• Starting Enhanced Fake Detection API on port {port}")
    print(f"üåê Access web interface at: http://127.0.0.1:{port}")
    print(f"üìä API status at: http://127.0.0.1:{port}/status")
    
    try:
        uvicorn.run("api:app", host="127.0.0.1", port=port, reload=False)
    except Exception as e:
        print(f"‚ùå Server error: {e}")
        input("Press Enter to exit...")
